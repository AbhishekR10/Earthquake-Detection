{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMuh/3WGd+djRixouHaDNwP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Cyo6Q4yBHxSm"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","source":["data = pd.read_csv('database.csv')\n","data"],"metadata":{"id":"rp3Mbaa0JHWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head(10)"],"metadata":{"id":"n1kqtWtCJMWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.describe()"],"metadata":{"id":"8jeiHjacJO-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.columns"],"metadata":{"id":"MDHEBFgJJSTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Since the data is random, so we need to scale it based on the model inputs. In this, we convert the given date and time to Unix time which is in seconds and a number.\n","import datetime\n","import time\n","import os\n","import calendar\n","timestamp = []\n","for date, time in zip(data['Date'], data['Time']):\n","    try:\n","        ts = datetime.datetime.strptime(date+' '+time, '%m/%d/%Y %H:%M:%S')\n","        timestamp.append(calendar.timegm(ts.timetuple()))\n","    except ValueError:\n","\n","        timestamp.append('ValueError')\n","timeStamp = pd.Series(timestamp)\n","data['Timestamp'] = timeStamp.values\n","final_data = data.drop(['Date', 'Time'], axis=1)\n","final_data = final_data[final_data.Timestamp != 'ValueError']\n","final_data.head()"],"metadata":{"id":"9R5J7RqxJX5j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install Cartopy\n"],"metadata":{"id":"GYXLojgAL_XQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import cartopy.crs as ccrs\n","import cartopy.feature as cfeature\n","\n","# Define data source with longitudes and latitudes\n","longitudes = data[\"Longitude\"]\n","latitudes = data[\"Latitude\"]\n","\n","# Create a plot with an appropriate projection\n","fig = plt.figure(figsize=(12, 10))\n","ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())   #the function has following description:It is effectively the geographic coordinate system where positions are given directly in latitude and longitude degrees. This projection is especially useful for world maps where distortion is acceptable and the simplicity of the projection aids in clear, straightforward representation of global data.\n","ax.set_title(\"All affected areas\")\n","\n","# Boundries\n","ax.set_extent([-180, 180, -80, 80], crs=ccrs.PlateCarree())\n","\n","# Plot the data points\n","ax.plot(longitudes, latitudes, \"o\", markersize=2, color='blue', transform=ccrs.Geodetic())\n","\n","# Adding map features\n","ax.add_feature(cfeature.COASTLINE)\n","ax.add_feature(cfeature.LAND, color='coral')\n","ax.add_feature(cfeature.OCEAN, color='aqua')\n","ax.add_feature(cfeature.BORDERS, linestyle=':')\n","plt.show()\n"],"metadata":{"id":"88cg89-rMeMw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = final_data[['Timestamp', 'Latitude', 'Longitude']]\n","y = final_data[['Magnitude', 'Depth']]\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","print(X_train.shape, X_test.shape, y_train.shape, X_test.shape)"],"metadata":{"id":"v0PWQNdWNce7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","def createthemodel(neurons, activation, optimizer, loss):\n","  model = Sequential()\n","  model.add(Dense(neurons,activation = activation,input_shape = (3,)))\n","  model.add(Dense(neurons,activation = activation))\n","  model.add(Dense(2,activation = 'softmax'))\n","  model.compile(optimizer = optimizer,loss = loss,metrics = ['accuracy'])\n","  return model\n","# Create a neural network to fit the data from the training set. The neural network will consist of three dense layers each with 16, 16, 2 nodes and reread. Relu and softmax will be used as activation functions."],"metadata":{"id":"6NMEgVrANu6C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install scikeras"],"metadata":{"id":"37M2HnNaOjbb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create a Random Forest Classifier\n","rf_classifier = RandomForestClassifier()\n","\n","# Define the parameter grid to search through\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [None, 10, 20],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Create GridSearchCV object\n","grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, verbose=1)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters and best score\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score:\", grid_search.best_score_)\n","\n","# Evaluate the model on the test set\n","best_rf_classifier = grid_search.best_estimator_\n","y_pred = best_rf_classifier.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Test Accuracy:\", accuracy)\n"],"metadata":{"id":"QVXykGaHSQuy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(16, activation='relu', input_shape=(3,)))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(2, activation='softmax'))\n","\n","model.compile(optimizer='SGD', loss='squared_hinge', metrics=['accuracy'])\n","model.fit(X_train, y_train, batch_size=10, epochs=20, verbose=1, validation_data=(X_test, y_test))\n","\n","[test_loss, test_acc] = model.evaluate(X_test, y_test)\n","print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"],"metadata":{"id":"G8tRsn6xVdAa"},"execution_count":null,"outputs":[]}]}